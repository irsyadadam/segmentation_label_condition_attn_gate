{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3619ca1-2294-4bba-8bbc-6935d551610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6155a350-fb2c-49f5-aa07-04cfd8764943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testImages  trainImages  trainMasks  trainSet.csv\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b32552-3736-48be-934c-8a589a910f07",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922f5d59-ac32-4d11-b29b-fe569ec3f5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageID</th>\n",
       "      <th>status</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1164</td>\n",
       "      <td>1</td>\n",
       "      <td>16165 16166 16167 16168 16169 16678 16679 1668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1169</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1171</td>\n",
       "      <td>1</td>\n",
       "      <td>58682 58683 58684 58685 58686 59194 59195 5919...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1177</td>\n",
       "      <td>1</td>\n",
       "      <td>125642 125643 125644 125645 125646 126155 1261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1178</td>\n",
       "      <td>1</td>\n",
       "      <td>53951 53952 53953 53954 53955 54463 54464 5446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>20408</td>\n",
       "      <td>1</td>\n",
       "      <td>61293 61294 61295 61296 61297 61804 61805 6180...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>20410</td>\n",
       "      <td>1</td>\n",
       "      <td>78295 78805 78806 78807 79316 79317 79318 7931...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>20594</td>\n",
       "      <td>1</td>\n",
       "      <td>61197 61198 61199 61200 61201 61709 61710 6171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>20605</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>20692</td>\n",
       "      <td>1</td>\n",
       "      <td>110405 110406 110407 110408 110409 110917 1109...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     imageID  status                                               mask\n",
       "0       1164       1  16165 16166 16167 16168 16169 16678 16679 1668...\n",
       "1       1169       0                                               -100\n",
       "2       1171       1  58682 58683 58684 58685 58686 59194 59195 5919...\n",
       "3       1177       1  125642 125643 125644 125645 125646 126155 1261...\n",
       "4       1178       1  53951 53952 53953 53954 53955 54463 54464 5446...\n",
       "..       ...     ...                                                ...\n",
       "500    20408       1  61293 61294 61295 61296 61297 61804 61805 6180...\n",
       "501    20410       1  78295 78805 78806 78807 79316 79317 79318 7931...\n",
       "502    20594       1  61197 61198 61199 61200 61201 61709 61710 6171...\n",
       "503    20605       0                                               -100\n",
       "504    20692       1  110405 110406 110407 110408 110409 110917 1109...\n",
       "\n",
       "[505 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/\"\n",
    "train_df = pd.read_csv(data_dir + \"trainSet.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbf335a-6264-491a-8f21-de05d131b919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "1    352\n",
       "0    153\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e697271-cd0a-4d19-875f-94ff4c433808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'data/trainImages/trainImages': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls data/trainImages/trainImages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5344cb9-f160-4017-ba83-3106353e1ca4",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076c7859-f955-455a-87de-3357f96d3d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: width = 512, height = 512\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = \"data/trainImages/4826.jpg\"\n",
    "\n",
    "# Open image\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# Get original size (width, height)\n",
    "width, height = img.size\n",
    "\n",
    "print(f\"Original size: width = {width}, height = {height}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61157329-b1ad-4047-985d-c9b10a597a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class LungCTNeedleDatasetV2(Dataset):\n",
    "    def __init__(self, csv_path, image_dir, image_size=(512, 512), use_ignore_index=True):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.image_dir = image_dir\n",
    "        self.image_size = image_size  # (H, W)\n",
    "        self.use_ignore_index = use_ignore_index  # True → fill mask with -100 when label == 0\n",
    "\n",
    "\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),  # [1, H, W]\n",
    "        ])\n",
    "\n",
    "\n",
    "    def _parse_mask(self, mask_str, label):\n",
    "        H, W = self.image_size\n",
    "        if str(mask_str).strip() == \"-100\" or label == 0:\n",
    "            fill_value = -100.0 if self.use_ignore_index else 0.0\n",
    "            return torch.full((1, H, W), fill_value, dtype=torch.float32)\n",
    "\n",
    "        mask = torch.zeros(H * W, dtype=torch.float32)\n",
    "        try:\n",
    "            indices = list(map(int, mask_str.strip().split()))\n",
    "            indices = [i for i in indices if 0 <= i < H * W]\n",
    "            mask[indices] = 1.0\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] Failed parsing mask: {mask_str} — {e}\")\n",
    "        return mask.view(1, H, W)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        patient_id = str(row['imageID'])\n",
    "        label = int(row['status'])\n",
    "        mask_str = row['mask']\n",
    "\n",
    "        # Load image\n",
    "        image_path = os.path.join(self.image_dir, f\"{patient_id}.jpg\")\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        image = self.image_transform(image)  # [1, H, W]\n",
    "\n",
    "        # Create mask\n",
    "        mask = self._parse_mask(mask_str, label)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32), mask, patient_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9cb8776-9936-49b0-8857-cbd38b2277dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LungCTNeedleDatasetV2(\n",
    "    csv_path=\"data/trainSet.csv\",\n",
    "    image_dir=\"data/trainImages\",\n",
    "    image_size=(512, 512),\n",
    "    use_ignore_index=True  # set to False if you want zero-filled instead\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85302787-f6a6-46a5-b15c-02febd4f03c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 512, 512])\n",
      "torch.Size([4, 1, 512, 512])\n",
      "tensor([1., 0., 1., 1.])\n",
      "('9574', '6373', '2319', '16184')\n"
     ]
    }
   ],
   "source": [
    "for image, label, mask, patient_id in dataloader:\n",
    "    print(image.shape)     # [B, 1, 512, 512]\n",
    "    print(mask.shape)      # [B, 1, 512, 512]\n",
    "    print(label) \n",
    "    print(patient_id)      # List[str]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56547507-c3c4-4fa5-aaa6-da67dead4429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageID</th>\n",
       "      <th>status</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>16042</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imageID  status  mask\n",
       "378    16042       0  -100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"imageID\"] == 16042]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5238da-aae1-4ceb-afd7-4da4871899b1",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e729603d-4ce8-415a-b9c0-491b7f2a1553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/iadam/.cache/torch/hub/Warvito_radimagenet-models_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "pretrained_backbone = torch.hub.load(\"Warvito/radimagenet-models\", 'radimagenet_resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3b5c18b-4952-4ec5-961d-1aeae5241ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c8b484-137a-45b5-96f8-7666c19db1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from radimagenet_models.models.resnet import radimagenet_resnet50\n",
    "\n",
    "# --------------------------\n",
    "# ASPP Module for multi-scale context\n",
    "# --------------------------\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
    "        self.conv12 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
    "        self.conv18 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=18, dilation=18)\n",
    "        self.out_conv = nn.Conv2d(out_channels * 4, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv6(x)\n",
    "        x3 = self.conv12(x)\n",
    "        x4 = self.conv18(x)\n",
    "        x_cat = torch.cat([x1, x2, x3, x4], dim=1)\n",
    "        return self.out_conv(x_cat)\n",
    "\n",
    "# --------------------------\n",
    "# Improved AttentionGatedUNet with ASPP and deep supervision\n",
    "# --------------------------\n",
    "class NeedleSegmentationNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, feature_dim=2048):\n",
    "        super().__init__()\n",
    "        self.encoder = radimagenet_resnet50()\n",
    "\n",
    "        if in_channels == 1:\n",
    "            old_conv = self.encoder.conv1\n",
    "            new_conv = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "            with torch.no_grad():\n",
    "                new_conv.weight.copy_(old_conv.weight.mean(dim=1, keepdim=True))\n",
    "            self.encoder.conv1 = new_conv\n",
    "\n",
    "        self.enc1 = nn.Sequential(self.encoder.conv1, self.encoder.bn1, self.encoder.relu)\n",
    "        self.enc2 = self.encoder.layer1\n",
    "        self.enc3 = self.encoder.layer2\n",
    "        self.enc4 = self.encoder.layer3\n",
    "        self.enc5 = self.encoder.layer4\n",
    "\n",
    "        # ASPP on the deepest features\n",
    "        self.aspp = ASPP(2048, 256)\n",
    "\n",
    "        self.up4 = self._upblock(256, 128)\n",
    "        self.up3 = self._upblock(128, 64)\n",
    "        self.up2 = self._upblock(64, 32)\n",
    "        self.up1 = self._upblock(32, 16)\n",
    "\n",
    "        self.segmentation_head = nn.Conv2d(16, 1, kernel_size=1)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048, 1)\n",
    "        )\n",
    "\n",
    "    def _upblock(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def _align_skip(self, x, skip):\n",
    "        if x.shape[-2:] != skip.shape[-2:]:\n",
    "            x = F.interpolate(x, size=skip.shape[-2:], mode='bilinear', align_corners=True)\n",
    "        return x + skip\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)       # [B, 64, 256, 256]\n",
    "        e2 = self.enc2(e1)      # [B, 256, 128, 128]\n",
    "        e3 = self.enc3(e2)      # [B, 512, 64, 64]\n",
    "        e4 = self.enc4(e3)      # [B, 1024, 32, 32]\n",
    "        e5 = self.enc5(e4)      # [B, 2048, 16, 16]\n",
    "\n",
    "        gated = self.aspp(e5)   # ASPP context [B, 256, 16, 16]\n",
    "\n",
    "        d4 = self._align_skip(self.up4(gated), e4)\n",
    "        d3 = self._align_skip(self.up3(d4), e3)\n",
    "        d2 = self._align_skip(self.up2(d3), e2)\n",
    "        d1 = self._align_skip(self.up1(d2), e1)\n",
    "\n",
    "        seg_mask = self.segmentation_head(d1)  # [B, 1, 512, 512]\n",
    "        class_logits = self.classifier(e5).squeeze(-1)\n",
    "\n",
    "        return {\n",
    "            \"segmentation\": seg_mask,\n",
    "            \"classification\": class_logits\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "398e154e-91cf-449f-9e25-550ba0503933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_tversky_loss(pred, target, alpha=0.3, beta=0.7, gamma=0.75, epsilon=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    tp = (pred * target).sum(dim=(1,2,3))\n",
    "    fp = ((1 - target) * pred).sum(dim=(1,2,3))\n",
    "    fn = (target * (1 - pred)).sum(dim=(1,2,3))\n",
    "    tversky = (tp + epsilon) / (tp + alpha * fp + beta * fn + epsilon)\n",
    "    return (1 - tversky) ** gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a7eaf50-41b2-4d7c-8c95-9e2526313dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_one_epoch_with_eval(model, dataloader, optimizer, device, scaler,\n",
    "                               lambda_cls=1.0, threshold=0.5, alpha=0.3, beta=0.7, gamma=0.75):\n",
    "    model.train()\n",
    "    cls_loss_fn = nn.BCEWithLogitsLoss()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    dice_total = 0.0\n",
    "    sens_total = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for images, labels, masks, _ in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            seg_pred = outputs['segmentation']\n",
    "            class_logits = outputs['classification']\n",
    "\n",
    "            if class_logits.ndim == 2:\n",
    "                class_logits = class_logits.squeeze(-1)\n",
    "\n",
    "            # Apply ignore index masking\n",
    "            valid_mask = (masks != -100)\n",
    "            pred_valid = seg_pred[valid_mask]\n",
    "            target_valid = masks[valid_mask]\n",
    "\n",
    "            # Focal Tversky Loss\n",
    "            loss_seg = focal_tversky_loss(pred_valid, target_valid,\n",
    "                                          alpha=alpha, beta=beta, gamma=gamma).mean()\n",
    "\n",
    "            # Classification loss\n",
    "            loss_cls = cls_loss_fn(class_logits, labels)\n",
    "            loss = loss_seg + lambda_cls * loss_cls\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # --- Metrics (only for positives) ---\n",
    "        needle_present = labels == 1\n",
    "        if needle_present.sum() > 0:\n",
    "            seg_pred_pos = torch.sigmoid(seg_pred[needle_present]) > threshold\n",
    "            gt_mask_pos = masks[needle_present]\n",
    "\n",
    "            preds_flat = seg_pred_pos.view(seg_pred_pos.size(0), -1)\n",
    "            masks_flat = gt_mask_pos.view(gt_mask_pos.size(0), -1)\n",
    "\n",
    "            intersection = (preds_flat * masks_flat).sum(dim=1)\n",
    "            dice = (2. * intersection) / (preds_flat.sum(dim=1) + masks_flat.sum(dim=1) + 1e-8)\n",
    "            TP = intersection\n",
    "            FN = ((~preds_flat.bool()) * masks_flat.bool()).sum(dim=1)\n",
    "            sens = TP / (TP + FN + 1e-8)\n",
    "\n",
    "            dice_total += dice.sum().item()\n",
    "            sens_total += sens.sum().item()\n",
    "            count += preds_flat.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_dice = dice_total / count if count > 0 else 0.0\n",
    "    avg_sens = sens_total / count if count > 0 else 0.0\n",
    "\n",
    "    return avg_loss, avg_dice, avg_sens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c1e465-c268-4973-b956-04fd678368ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iadam/miniconda3/envs/thyroid_vision_CUDA/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Training Progress:   0%|                                                                                                                                             | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Progress\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     loss, dice, sens \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch_with_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlambda_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# classification loss weight\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# use your best threshold\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# focal tversky params\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(loss)  \u001b[38;5;66;03m# reduce LR on plateau\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Dice: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdice\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Sensitivity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msens\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 22\u001b[0m, in \u001b[0;36mtrain_one_epoch_with_eval\u001b[0;34m(model, dataloader, optimizer, device, scaler, lambda_cls, threshold, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[0;32m---> 22\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     seg_pred \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegmentation\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     24\u001b[0m     class_logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/thyroid_vision_CUDA/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thyroid_vision_CUDA/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 77\u001b[0m, in \u001b[0;36mNeedleSegmentationNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 77\u001b[0m     e1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m# [B, 64, 256, 256]\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     e2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc2(e1)      \u001b[38;5;66;03m# [B, 256, 128, 128]\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     e3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc3(e2)      \u001b[38;5;66;03m# [B, 512, 64, 64]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thyroid_vision_CUDA/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thyroid_vision_CUDA/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thyroid_vision_CUDA/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/thyroid_vision_CUDA/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thyroid_vision_CUDA/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/thyroid_vision_CUDA/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/thyroid_vision_CUDA/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_epochs = 200\n",
    "train_loader = dataloader  # your dataloader for train set\n",
    "\n",
    "# Initialize model, optimizer, scaler\n",
    "model = NeedleSegmentationNet(in_channels=1).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Optional: scheduler (adaptive LR if loss plateaus)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Start training\n",
    "for epoch in tqdm(range(num_epochs), desc='Training Progress'):\n",
    "    loss, dice, sens = train_one_epoch_with_eval(\n",
    "        model, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        device, \n",
    "        scaler,\n",
    "        lambda_cls=1.0,         # classification loss weight\n",
    "        threshold=0.3,           # use your best threshold\n",
    "        alpha=0.3, beta=0.7, gamma=0.75  # focal tversky params\n",
    "    )\n",
    "    scheduler.step(loss)  # reduce LR on plateau\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {loss:.4f} | Dice: {dice:.4f} | Sensitivity: {sens:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3228e277-d168-4631-8918-69e483a40a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "torch.save(model.state_dict(), \"attn_gated_0.73DICE_0.72SENSE.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86d87321-79ad-400c-83f9-bd3dbebe5093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testImages  trainImages  trainMasks  trainSet.csv\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb7b52-e035-4306-928e-cd09bcfaca7b",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f416e310-a4ae-46e8-9a51-fcf3d9224311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungCTTestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, image_size=(512, 512)):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_size = image_size\n",
    "        self.image_paths = sorted([\n",
    "            f for f in os.listdir(image_dir) if f.endswith(\".jpg\")\n",
    "        ], key=lambda x: int(x.split('.')[0]))  # assumes filenames like 1164.jpg\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.image_paths[idx]\n",
    "        image_path = os.path.join(self.image_dir, filename)\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        image = self.transform(image)\n",
    "        image_id = int(filename.split('.')[0])  # extract numeric ID\n",
    "        return image, image_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "061e44d0-5a44-463d-b9e3-8a7f4845e811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionGatedUNet(\n",
       "  (encoder): ResNet50(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (bn1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn3): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (enc1): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1.001e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (enc2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (enc3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (enc4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (enc5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1.001e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (attn_gate): Sequential(\n",
       "    (0): Conv2d(2048, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (up4): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (1): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (up3): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (up2): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (up1): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (up0): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (segmentation_head): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=1)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "final_model = AttentionGatedUNet()\n",
    "final_model.load_state_dict(torch.load(\"attn_gated_0.73DICE_0.72SENSE.pth\", map_location=device))  # replace with your model path\n",
    "final_model.to(device)\n",
    "final_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38066022-2cca-4078-99e0-2737fd96437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LungCTTestDataset(image_dir=\"data/testImages\", image_size=(512, 512))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3fc9714-a7e5-4442-90f2-9a0b5442812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "os.makedirs(\"predicted_masks\", exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, image_ids in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = final_model(images)\n",
    "        seg_logits = outputs['segmentation']  # [B, 1, 512, 512]\n",
    "        seg_probs = torch.sigmoid(seg_logits)\n",
    "        seg_bin = (seg_probs > 0.5).float()  # Binarize to [0,1]\n",
    "\n",
    "        for i in range(images.size(0)):\n",
    "            mask = seg_bin[i]  # [1, 512, 512]\n",
    "            image_id = image_ids[i]\n",
    "            save_path = os.path.join(\"predicted_masks\", f\"{image_id}_pred.png\")\n",
    "            save_image(mask, save_path)  # Will be scaled to 0–255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d46b905d-16e4-46cc-8493-06ca470eca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImages(imgDirectory: str, saveDirectory: str = os.getcwd(), returnDF:bool = False):\n",
    "    \"\"\"\n",
    "    Process binarized predicted mask images saved in a directory, implement checks, \n",
    "    and create a `'submission.csv'` submission file containing image status and mask indices.\n",
    "\n",
    "    **Do NOT modify this function.**\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgDirectory : str\n",
    "        The directory containing the images to be processed. It should have exactly 127 .png files.\n",
    "        When you save your model's predicted masks, make sure the pixel values \n",
    "        are either 0 or 255, and save it as a .png file (preferably using PIL).\n",
    "    saveDirectory : str, optional\n",
    "        The directory where the resulting DataFrame will be saved as a CSV file. \n",
    "        Defaults to the current directory.\n",
    "    returnDF : bool, optional\n",
    "        Whether to return the DataFrame. Defaults to False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: A DataFrame with columns 'imageID', 'status', and 'mask', indexed by 'imageID' if `returnDF` is True, else None\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the number of .png files in `imgDirectory` is not 127,\n",
    "        if any image is not binary, or if any image is not 512x512 pixels.\n",
    "\n",
    "    Example Usage\n",
    "    -------------\n",
    "    `processImages('path/to/img/folder', 'path/to/save/folder')`\n",
    "    \"\"\"\n",
    "\n",
    "    files = [f for f in os.listdir(imgDirectory) if f.endswith('.png')]  # Get all .png files in the directory\n",
    "    if len(files) != 127:\n",
    "        raise ValueError(\"Directory must contain exactly 127 .png files\")\n",
    "\n",
    "    files.sort(key=lambda x: int(x.split('_')[0]))  # Sort the files\n",
    "\n",
    "    data = []  # List of dictionaries to be converted to DataFrame\n",
    "    for file in files:\n",
    "        imgPath = os.path.join(imgDirectory, file)\n",
    "        img = np.array(Image.open(imgPath).convert('L'), dtype=np.uint8)\n",
    "\n",
    "        # Check if image is binary\n",
    "        if not np.array_equal(img, img.astype(bool).astype(img.dtype) * 255):\n",
    "            raise ValueError(f\"Image {file} is not binary\")\n",
    "        # Check image size\n",
    "        if img.shape != (512, 512):\n",
    "            raise ValueError(f\"Image {file} is not of size 512x512\")\n",
    "\n",
    "        status = 1 if np.any(img == 255) else 0  # Determine status of image\n",
    "        maskIndices = ' '.join(map(str, np.nonzero(img.flatten() == 255)[0])) if status else '-100'\n",
    "\n",
    "        data.append({'imageID': int(file.split('_')[0]), 'status': status, 'mask': maskIndices})\n",
    "\n",
    "    df = pd.DataFrame(data).set_index('imageID')\n",
    "    df.to_csv(os.path.join(saveDirectory, 'submission.csv'))\n",
    "\n",
    "    if returnDF: return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07b37dfe-40f7-4423-af11-7d047e8c1cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "processImages(imgDirectory=\"predicted_masks\", saveDirectory=\".\", returnDF=False)\n",
    "print(\"✅ Submission saved to submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b343ae49-f020-460a-8418-c4ca19e0dd5c",
   "metadata": {},
   "source": [
    "## Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69d1dfa5-e061-4b22-a727-f8d7c21f8e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 127/127 [00:23<00:00,  5.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Folder to save predicted raw probabilities\n",
    "os.makedirs(\"train_raw_probs\", exist_ok=True)\n",
    "os.makedirs(\"train_gt_masks\", exist_ok=True)\n",
    "\n",
    "final_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, masks, patient_ids in tqdm(dataloader):\n",
    "        images = images.cuda()\n",
    "        outputs = final_model(images)\n",
    "        seg_logits = outputs['segmentation']  # [B, 1, 512, 512]\n",
    "        seg_probs = torch.sigmoid(seg_logits)  # Probabilities between 0 and 1\n",
    "\n",
    "        for i in range(images.size(0)):\n",
    "            prob_map = seg_probs[i].cpu()  # [1, 512, 512]\n",
    "            gt_mask = masks[i].cpu()       # [1, 512, 512]\n",
    "            image_id = patient_ids[i]\n",
    "\n",
    "            torch.save(prob_map, f\"train_raw_probs/{image_id}.pt\")\n",
    "            torch.save(gt_mask, f\"train_gt_masks/{image_id}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd037ea9-5dd9-433f-be26-dc04f310197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def dice_score(pred, target, epsilon=1e-6):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    return (2 * intersection + epsilon) / (union + epsilon)\n",
    "\n",
    "def sensitivity_score(pred, target, epsilon=1e-6):\n",
    "    # Sensitivity = TP / (TP + FN)\n",
    "    tp = (pred * target).sum()\n",
    "    fn = ((1 - pred) * target).sum()\n",
    "    return (tp + epsilon) / (tp + fn + epsilon)\n",
    "\n",
    "# Weights\n",
    "alpha = 0.7  # You can adjust this (e.g., 0.5 if you want equal weight)\n",
    "\n",
    "# Thresholds to try\n",
    "thresholds = [round(x, 2) for x in torch.arange(0.3, 0.71, 0.05).tolist()]\n",
    "results = {}\n",
    "\n",
    "prob_files = sorted([f for f in os.listdir(\"train_raw_probs\") if f.endswith(\".pt\")], key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "for threshold in thresholds:\n",
    "    all_dice = []\n",
    "    all_sens = []\n",
    "    for file in prob_files:\n",
    "        prob_map = torch.load(os.path.join(\"train_raw_probs\", file))  # [1, H, W]\n",
    "        gt_mask = torch.load(os.path.join(\"train_gt_masks\", file))    # [1, H, W]\n",
    "\n",
    "        pred_mask = (prob_map > threshold).float()\n",
    "\n",
    "        valid = (gt_mask != -100)\n",
    "        pred_mask = pred_mask[valid]\n",
    "        gt_mask_clean = gt_mask[valid]\n",
    "\n",
    "        dice = dice_score(pred_mask, gt_mask_clean)\n",
    "        sens = sensitivity_score(pred_mask, gt_mask_clean)\n",
    "\n",
    "        all_dice.append(dice.item())\n",
    "        all_sens.append(sens.item())\n",
    "\n",
    "    avg_dice = np.mean(all_dice)\n",
    "    avg_sens = np.mean(all_sens)\n",
    "    combined_score = alpha * avg_dice + (1 - alpha) * avg_sens\n",
    "\n",
    "    results[threshold] = {\n",
    "        \"dice\": avg_dice,\n",
    "        \"sensitivity\": avg_sens,\n",
    "        \"combined\": combined_score\n",
    "    }\n",
    "\n",
    "    print(f\"Threshold {threshold:.2f} | Dice: {avg_dice:.4f} | Sensitivity: {avg_sens:.4f} | Score: {combined_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cff765c-5592-4624-ad5d-1e6304191714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best Threshold: 0.3 — Combined Score: 0.8385 | Dice: 0.8260 | Sensitivity: 0.8678\n"
     ]
    }
   ],
   "source": [
    "# Find best threshold based on combined score\n",
    "best_threshold = max(results, key=lambda t: results[t][\"combined\"])\n",
    "best_score = results[best_threshold][\"combined\"]\n",
    "best_dice = results[best_threshold][\"dice\"]\n",
    "best_sens = results[best_threshold][\"sensitivity\"]\n",
    "\n",
    "print(f\"\\n✅ Best Threshold: {best_threshold} — Combined Score: {best_score:.4f} | Dice: {best_dice:.4f} | Sensitivity: {best_sens:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8d918-db39-4ea9-a81c-057e96574d54",
   "metadata": {},
   "source": [
    "## Apply to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cfa6f59-018b-4c4b-87b0-58c46d011c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "threshold = 0.3  # 🟢 Use the best threshold from train set\n",
    "\n",
    "os.makedirs(\"predicted_masks_thresh_0.3\", exist_ok=True)\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, image_ids in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = final_model(images)\n",
    "        seg_probs = torch.sigmoid(outputs['segmentation'])  # [B, 1, 512, 512]\n",
    "        seg_bin = (seg_probs > threshold).float()\n",
    "\n",
    "        for i in range(images.size(0)):\n",
    "            mask = seg_bin[i]  # [1, 512, 512]\n",
    "            image_id = image_ids[i]\n",
    "            save_path = os.path.join(\"predicted_masks_thresh_0.3\", f\"{image_id}_pred.png\")\n",
    "            save_image(mask, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f086493e-d742-493f-b49e-7d171b441098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ submission.csv created using threshold = 0.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "processImages(\n",
    "    imgDirectory=\"predicted_masks_thresh_0.3\",\n",
    "    saveDirectory=\".\",\n",
    "    returnDF=False\n",
    ")\n",
    "\n",
    "print(\"✅ submission.csv created using threshold = 0.3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68772c59-6d8c-4874-af62-5bab58e8da57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thyroid_CUDA",
   "language": "python",
   "name": "thyroid_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
